{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# IMDB reviews as n-gram graphs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72f07ee26072853b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This example shows how to use n-gram graphs with the imdb review dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb3164a1141c375d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a211f5be32286e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip3 install datasets scikit-learn nltk\n",
    "!pip install -q dgl -f https://data.dgl.ai/wheels/cu118/repo.html\n",
    "!pip install -q dglgo -f https://data.dgl.ai/wheels-test/repo.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac8fd6403f693050"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ee8522358180798"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download the imdb review dataset from huggingface:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd4d901f7629ec57"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['text', 'label'],\n        num_rows: 50000\n    })\n})"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:55:20.839249168Z",
     "start_time": "2023-12-13T20:55:07.248715129Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fd0c6f1d1e98089"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we can start, we have to preprocess the text. We remove punctuation, stop words, and break sentences into words. We use the nltk package to accomplish this:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff7beadab2b253cc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import TweetTokenizer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tokenizer_words = TweetTokenizer()\n",
    "\n",
    "\n",
    "def preprocess_text(sample):\n",
    "    text = sample[\"text\"]\n",
    "    text = text.lower()\n",
    "    text = tokenizer_words.tokenize(text)\n",
    "    text = [w for w in text if not w in stop_words and w.isalpha()]\n",
    "    return {\"text\": text}\n",
    "\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(preprocess_text)\n",
    "dataset[\"test\"] = dataset[\"test\"].map(preprocess_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:55:22.010233513Z",
     "start_time": "2023-12-13T20:55:20.815748855Z"
    }
   },
   "id": "d63c4114eb911555"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['rented',\n 'video',\n 'store',\n 'controversy',\n 'surrounded',\n 'first',\n 'released',\n 'also',\n 'heard',\n 'first',\n 'seized',\n 'u',\n 'customs',\n 'ever',\n 'tried',\n 'enter',\n 'country',\n 'therefore',\n 'fan',\n 'films',\n 'considered',\n 'controversial',\n 'really',\n 'see',\n 'br',\n 'br',\n 'plot',\n 'centered',\n 'around',\n 'young',\n 'swedish',\n 'drama',\n 'student',\n 'named',\n 'lena',\n 'wants',\n 'learn',\n 'everything',\n 'life',\n 'particular',\n 'wants',\n 'focus',\n 'attentions',\n 'making',\n 'sort',\n 'documentary',\n 'average',\n 'swede',\n 'thought',\n 'certain',\n 'political',\n 'issues',\n 'vietnam',\n 'war',\n 'race',\n 'issues',\n 'united',\n 'states',\n 'asking',\n 'politicians',\n 'ordinary',\n 'denizens',\n 'stockholm',\n 'opinions',\n 'politics',\n 'sex',\n 'drama',\n 'teacher',\n 'classmates',\n 'married',\n 'men',\n 'br',\n 'br',\n 'kills',\n 'years',\n 'ago',\n 'considered',\n 'pornographic',\n 'really',\n 'sex',\n 'nudity',\n 'scenes',\n 'far',\n 'even',\n 'shot',\n 'like',\n 'cheaply',\n 'made',\n 'porno',\n 'countrymen',\n 'mind',\n 'find',\n 'shocking',\n 'reality',\n 'sex',\n 'nudity',\n 'major',\n 'staple',\n 'swedish',\n 'cinema',\n 'even',\n 'ingmar',\n 'bergman',\n 'arguably',\n 'answer',\n 'good',\n 'old',\n 'boy',\n 'john',\n 'ford',\n 'sex',\n 'scenes',\n 'films',\n 'br',\n 'br',\n 'commend',\n 'filmmakers',\n 'fact',\n 'sex',\n 'shown',\n 'film',\n 'shown',\n 'artistic',\n 'purposes',\n 'rather',\n 'shock',\n 'people',\n 'make',\n 'money',\n 'shown',\n 'pornographic',\n 'theaters',\n 'america',\n 'good',\n 'film',\n 'anyone',\n 'wanting',\n 'study',\n 'meat',\n 'potatoes',\n 'pun',\n 'intended',\n 'swedish',\n 'cinema',\n 'really',\n 'film',\n 'much',\n 'plot']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"text\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:55:24.082424217Z",
     "start_time": "2023-12-13T20:55:22.009665125Z"
    }
   },
   "id": "ee928cb5dc8be076"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build N-Gram Graphs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c92a1a533d7d98f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can build the n-gram graphs for these texts:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6ff0b4e7e93798e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "from ngram_graph.graph import text_to_graph\n",
    "\n",
    "\n",
    "def get_edges(samples):\n",
    "    graphs = [text_to_graph(t, n=4) for t in samples[\"text\"]]\n",
    "    graphs = [g.as_dgl_graph() for g in graphs]\n",
    "    return {\n",
    "        \"edges\": [g[0].edges() for g in graphs],\n",
    "        \"n_grams\": [g[1] for g in graphs],\n",
    "    }\n",
    "\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(get_edges, batched=True, batch_size=100, num_proc=os.cpu_count())\n",
    "dataset[\"test\"] = dataset[\"test\"].map(get_edges, batched=True, batch_size=100, num_proc=os.cpu_count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:55:27.424956873Z",
     "start_time": "2023-12-13T20:55:24.083886720Z"
    }
   },
   "id": "b33c06c0ba1103fb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['rented video store controversy',\n 'video store controversy surrounded',\n 'store controversy surrounded first',\n 'controversy surrounded first released',\n 'surrounded first released also',\n 'first released also heard',\n 'released also heard first',\n 'also heard first seized',\n 'heard first seized u',\n 'first seized u customs',\n 'seized u customs ever',\n 'u customs ever tried',\n 'customs ever tried enter',\n 'ever tried enter country',\n 'tried enter country therefore',\n 'enter country therefore fan',\n 'country therefore fan films',\n 'therefore fan films considered',\n 'fan films considered controversial',\n 'films considered controversial really',\n 'considered controversial really see',\n 'controversial really see br',\n 'really see br br',\n 'see br br plot',\n 'br br plot centered',\n 'br plot centered around',\n 'plot centered around young',\n 'centered around young swedish',\n 'around young swedish drama',\n 'young swedish drama student',\n 'swedish drama student named',\n 'drama student named lena',\n 'student named lena wants',\n 'named lena wants learn',\n 'lena wants learn everything',\n 'wants learn everything life',\n 'learn everything life particular',\n 'everything life particular wants',\n 'life particular wants focus',\n 'particular wants focus attentions',\n 'wants focus attentions making',\n 'focus attentions making sort',\n 'attentions making sort documentary',\n 'making sort documentary average',\n 'sort documentary average swede',\n 'documentary average swede thought',\n 'average swede thought certain',\n 'swede thought certain political',\n 'thought certain political issues',\n 'certain political issues vietnam',\n 'political issues vietnam war',\n 'issues vietnam war race',\n 'vietnam war race issues',\n 'war race issues united',\n 'race issues united states',\n 'issues united states asking',\n 'united states asking politicians',\n 'states asking politicians ordinary',\n 'asking politicians ordinary denizens',\n 'politicians ordinary denizens stockholm',\n 'ordinary denizens stockholm opinions',\n 'denizens stockholm opinions politics',\n 'stockholm opinions politics sex',\n 'opinions politics sex drama',\n 'politics sex drama teacher',\n 'sex drama teacher classmates',\n 'drama teacher classmates married',\n 'teacher classmates married men',\n 'classmates married men br',\n 'married men br br',\n 'men br br kills',\n 'br br kills years',\n 'br kills years ago',\n 'kills years ago considered',\n 'years ago considered pornographic',\n 'ago considered pornographic really',\n 'considered pornographic really sex',\n 'pornographic really sex nudity',\n 'really sex nudity scenes',\n 'sex nudity scenes far',\n 'nudity scenes far even',\n 'scenes far even shot',\n 'far even shot like',\n 'even shot like cheaply',\n 'shot like cheaply made',\n 'like cheaply made porno',\n 'cheaply made porno countrymen',\n 'made porno countrymen mind',\n 'porno countrymen mind find',\n 'countrymen mind find shocking',\n 'mind find shocking reality',\n 'find shocking reality sex',\n 'shocking reality sex nudity',\n 'reality sex nudity major',\n 'sex nudity major staple',\n 'nudity major staple swedish',\n 'major staple swedish cinema',\n 'staple swedish cinema even',\n 'swedish cinema even ingmar',\n 'cinema even ingmar bergman',\n 'even ingmar bergman arguably',\n 'ingmar bergman arguably answer',\n 'bergman arguably answer good',\n 'arguably answer good old',\n 'answer good old boy',\n 'good old boy john',\n 'old boy john ford',\n 'boy john ford sex',\n 'john ford sex scenes',\n 'ford sex scenes films',\n 'sex scenes films br',\n 'scenes films br br',\n 'films br br commend',\n 'br br commend filmmakers',\n 'br commend filmmakers fact',\n 'commend filmmakers fact sex',\n 'filmmakers fact sex shown',\n 'fact sex shown film',\n 'sex shown film shown',\n 'shown film shown artistic',\n 'film shown artistic purposes',\n 'shown artistic purposes rather',\n 'artistic purposes rather shock',\n 'purposes rather shock people',\n 'rather shock people make',\n 'shock people make money',\n 'people make money shown',\n 'make money shown pornographic',\n 'money shown pornographic theaters',\n 'shown pornographic theaters america',\n 'pornographic theaters america good',\n 'theaters america good film',\n 'america good film anyone',\n 'good film anyone wanting',\n 'film anyone wanting study',\n 'anyone wanting study meat',\n 'wanting study meat potatoes',\n 'study meat potatoes pun',\n 'meat potatoes pun intended',\n 'potatoes pun intended swedish',\n 'pun intended swedish cinema',\n 'intended swedish cinema really',\n 'swedish cinema really film',\n 'cinema really film much',\n 'really film much plot']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"n_grams\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:55:27.435387116Z",
     "start_time": "2023-12-13T20:55:27.430685410Z"
    }
   },
   "id": "5058ad5ae4d206ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "There can be empty graphs, because there are texts that do not contain more than N words after the pre-processing is done. So filter all empty graphs:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6326b8a7589fc0f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].filter(lambda sample: len(sample[\"edges\"][0]) != 0, num_proc=os.cpu_count())\n",
    "dataset[\"test\"] = dataset[\"test\"].filter(lambda sample: len(sample[\"edges\"][0]) != 0, num_proc=os.cpu_count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:55:27.492246932Z",
     "start_time": "2023-12-13T20:55:27.435154673Z"
    }
   },
   "id": "7d1c3ba2ce623dd3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "After we created the n-gram graphs, we have to vectorize the n-grams. For this purpose we use the CountVectorizer:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70c2dda50a6659a9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1587"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x, max_df=0.98, min_df=0.01)\n",
    "vectorizer.fit(dataset[\"train\"][\"text\"])\n",
    "vectorizer.fit(dataset[\"test\"][\"text\"])\n",
    "len(vectorizer.vocabulary_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:55:33.332771651Z",
     "start_time": "2023-12-13T20:55:27.493939498Z"
    }
   },
   "id": "b0dbf009c714d0c5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_ids = [vectorizer.transform(g) for g in dataset[\"train\"][\"n_grams\"]]\n",
    "test_ids = [vectorizer.transform(g) for g in dataset[\"test\"][\"n_grams\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:56:36.434484973Z",
     "start_time": "2023-12-13T20:55:33.333131671Z"
    }
   },
   "id": "8752e9b40473f0b4"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "\n",
    "\n",
    "def get_dgl_graphs(samples, ids):\n",
    "    graphs = [dgl.graph(tuple(s)) for s in samples[\"edges\"]]\n",
    "    for g, i in zip(graphs, ids):\n",
    "        g.ndata[\"id\"] = torch.tensor(i.todense(), dtype=torch.float32)\n",
    "    return graphs\n",
    "\n",
    "\n",
    "train_graphs = get_dgl_graphs(dataset[\"train\"], train_ids)\n",
    "test_graphs = get_dgl_graphs(dataset[\"test\"], test_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:58:27.016232269Z",
     "start_time": "2023-12-13T20:56:36.434399768Z"
    }
   },
   "id": "281cf7c6da167cd0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a final step, we will save the dgl graphs for future use:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0f576fdf1ca9c9a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dgl.save_graphs(\"train.bin\", train_graphs)\n",
    "dgl.save_graphs(\"test.bin\", test_graphs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T21:02:17.327567379Z",
     "start_time": "2023-12-13T20:58:27.029877034Z"
    }
   },
   "id": "6e3b8e910afd2593"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
